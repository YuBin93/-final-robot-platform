name: Scheduled Data Scraping

on:
  # 这个设置允许我们手动触发工作流，方便测试
  workflow_dispatch:

  # 这个设置是我们的“定时闹钟”
  schedule:
    # 每天在 UTC 时间凌晨2点运行 (大约是北京时间上午10点)
    # 注意下面这行正确的缩进！
    - cron: '0 2 * * *'

jobs:
  scrape:
    # 使用最新版的 ubuntu 服务器
    runs-on: ubuntu-latest

    steps:
      # 第一步：把我们的代码下载到服务器上
      - name: Checkout repository
        uses: actions/checkout@v4

      # 第二步：安装 Python 环境
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # 第三步：安装所有我们需要的 Python 库
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # 第四步：运行我们的爬虫脚本，并使用我们之前配置好的密钥
      - name: Run scraper to update data
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python scraper.py
